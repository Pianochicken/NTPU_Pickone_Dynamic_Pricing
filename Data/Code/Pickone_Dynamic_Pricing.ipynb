{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pickone_Dynamic_Pricing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-RW-2Zz6Bpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmf0A6-t_yt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd drive/My\\ Drive/Programmation\\ Data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jwpW8VU_zLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65DRGGqPV0td",
        "colab_type": "text"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcZgd1VjV4kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Delete unnecessary columns, and add 'price_per_size', 'locate_id' as new columns\n",
        "\n",
        "#####  space.csv處理  #####\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data_space = pd.read_csv(\"spaces.csv\", encoding = 'utf-8')\n",
        "\n",
        "#丟掉spaces.csv中我們不需要的欄位\n",
        "data_space = data_space.drop('pickone_no', axis = 1)\n",
        "data_space = data_space.drop('enabled', axis = 1)\n",
        "data_space = data_space.drop('created_at', axis = 1)\n",
        "data_space = data_space.drop('updated_at', axis = 1)\n",
        "data_space = data_space.drop('thumb', axis = 1)\n",
        "data_space = data_space.drop('county', axis = 1)\n",
        "data_space = data_space.drop('district', axis = 1)\n",
        "data_space = data_space.drop('address', axis = 1)\n",
        "data_space = data_space.drop('address_info', axis = 1)\n",
        "data_space = data_space.drop('brief', axis = 1)\n",
        "data_space = data_space.drop('use_info', axis = 1)\n",
        "data_space = data_space.drop('device_info', axis = 1)\n",
        "data_space = data_space.drop('floor_plan', axis = 1)\n",
        "data_space = data_space.drop('sort', axis = 1)\n",
        "\n",
        "#把space.csv中的id改名為space_id，並修正space103\n",
        "data_space.rename(columns = {data_space.columns[0]: 'space_id'}, inplace = True)\n",
        "data_space.loc[70,'price']=390\n",
        "data_space=data_space.sort_values(by='space_id')\n",
        "\n",
        "#定義price_per_size，並把space.csv中的id改名為space_id\n",
        "for i in range(len(data_space)):\n",
        "  data_space.loc[i,'price_per_size'] = data_space.loc[i,'price']/data_space.loc[i,'size']\n",
        "\n",
        "#####  分配locate_id  #####\n",
        "space_id_list  = data_space[\"space_id\"].tolist()\n",
        "space_lat_list = data_space[\"lat\"].tolist()\n",
        "space_lng_list = data_space[\"lng\"].tolist()\n",
        "\n",
        "for i in range(len(data_space)):\n",
        "  if (space_lat_list[i] == 25.035915300000003) & (space_lng_list[i]==121.54786010000001):\n",
        "    data_space.loc[i, 'locate_id'] = 1\n",
        "  if (space_lat_list[i] == 25.0331768) & (space_lng_list[i]==121.54449640000001):\n",
        "    data_space.loc[i, 'locate_id'] = 2\n",
        "  if (space_lat_list[i] == 25.0364536) & (space_lng_list[i]==121.54390490000002):\n",
        "    data_space.loc[i, 'locate_id'] = 3\n",
        "  if (space_lat_list[i] == 25.030610999999997) & (space_lng_list[i]==121.543764):\n",
        "    data_space.loc[i, 'locate_id'] = 4\n",
        "  if (space_lat_list[i] == 25.053975899999998) & (space_lng_list[i]==121.5505238):\n",
        "    data_space.loc[i, 'locate_id'] = 5\n",
        "  if (space_lat_list[i] == 25.059776) & (space_lng_list[i]==121.5439548):\n",
        "    data_space.loc[i, 'locate_id'] = 6\n",
        "  if (space_lat_list[i] == 25.031880800000003) & (space_lng_list[i]==121.51937209999998):\n",
        "    data_space.loc[i, 'locate_id'] = 7\n",
        "  if (space_lat_list[i] == 25.0460064) & (space_lng_list[i]==121.51917590000001):\n",
        "    data_space.loc[i, 'locate_id'] = 8\n",
        "  if (space_lat_list[i] == 25.051114600000002) & (space_lng_list[i]==121.5172929):\n",
        "    data_space.loc[i, 'locate_id'] = 9\n",
        "  if (space_lat_list[i] == 25.027279699999998) & (space_lng_list[i]==121.5220325):\n",
        "    data_space.loc[i, 'locate_id'] = 10\n",
        "  if (space_lat_list[i] == 25.027801) & (space_lng_list[i]==121.52216399999999):\n",
        "    data_space.loc[i, 'locate_id'] = 11\n",
        "  if (space_lat_list[i] == 25.0267416) & (space_lng_list[i]==121.52321740000001):\n",
        "    data_space.loc[i, 'locate_id'] = 12\n",
        "  if (space_lat_list[i] == 25.023839000000002) & (space_lng_list[i]==121.52452):\n",
        "    data_space.loc[i, 'locate_id'] = 13\n",
        "  if (space_lat_list[i] == 25.021983600000002) & (space_lng_list[i]==121.52707290000001):\n",
        "    data_space.loc[i, 'locate_id'] = 14\n",
        "  if (space_lat_list[i] == 25.048663) & (space_lng_list[i]==121.521975):\n",
        "    data_space.loc[i, 'locate_id'] = 15\n",
        "  if (space_lat_list[i] == 25.062593) & (space_lng_list[i]==121.5203831):\n",
        "    data_space.loc[i, 'locate_id'] = 16\n",
        "  if (space_lat_list[i] == 25.0486715) & (space_lng_list[i]==121.520779):\n",
        "    data_space.loc[i, 'locate_id'] = 17\n",
        "  if (space_lat_list[i] == 25.0414199) & (space_lng_list[i]==121.539546):\n",
        "    data_space.loc[i, 'locate_id'] = 18\n",
        "  if (space_lat_list[i] == 25.043712600000003) & (space_lng_list[i]==121.5421649):\n",
        "    data_space.loc[i, 'locate_id'] = 19\n",
        "  if (space_lat_list[i] == 25.033409) & (space_lng_list[i]==121.53136699999999):\n",
        "    data_space.loc[i, 'locate_id'] = 20\n",
        "  if (space_lat_list[i] == 25.054250500000002) & (space_lng_list[i]==121.53328020000001):\n",
        "    data_space.loc[i, 'locate_id'] = 21\n",
        "  if (space_lat_list[i] == 25.048142000000002) & (space_lng_list[i]==121.54451599999999):\n",
        "    data_space.loc[i, 'locate_id'] = 22\n",
        "  if (space_lat_list[i] == 25.033378) & (space_lng_list[i]==121.55668700000001):\n",
        "    data_space.loc[i, 'locate_id'] = 23\n",
        "  if (space_lat_list[i] == 25.034836) & (space_lng_list[i]==121.55385):\n",
        "    data_space.loc[i, 'locate_id'] = 24\n",
        "  if (space_lat_list[i] == 25.051274199999998) & (space_lng_list[i]==121.56328219999999):\n",
        "    data_space.loc[i, 'locate_id'] = 25\n",
        "  if (space_lat_list[i] == 25.051678699999997) & (space_lng_list[i]==121.5430588):\n",
        "    data_space.loc[i, 'locate_id'] = 26\n",
        "  if (space_lat_list[i] == 25.026835100000003) & (space_lng_list[i]==121.5432387):\n",
        "    data_space.loc[i, 'locate_id'] = 27\n",
        "  if (space_lat_list[i] == 25.041724) & (space_lng_list[i]==121.555095):\n",
        "    data_space.loc[i, 'locate_id'] = 28\n",
        "  if (space_lat_list[i] == 25.073901100000004) & (space_lng_list[i]==121.57859909999999):\n",
        "    data_space.loc[i, 'locate_id'] = 29\n",
        "  if (space_lat_list[i] == 25.0526598) & (space_lng_list[i]==121.54482900000001):\n",
        "    data_space.loc[i, 'locate_id'] = 30\n",
        "  if (space_lat_list[i] == 25.0047) & (space_lng_list[i]==121.538524):\n",
        "    data_space.loc[i, 'locate_id'] = 31\n",
        "  if (space_lat_list[i] == 25.048352899999998) & (space_lng_list[i]==121.5325303):\n",
        "    data_space.loc[i, 'locate_id'] = 32\n",
        "data_space=data_space.fillna(0)\n",
        "data_space=data_space[data_space['locate_id']>0] # 將不符合的space篩掉\n",
        "\n",
        "#####  刪除特定space_id #####\n",
        "data_space = data_space.loc[data_space['space_id']!=2]\n",
        "data_space = data_space.loc[data_space['space_id']!=61]\n",
        "data_space = data_space.loc[data_space['space_id']!=107]\n",
        "data_space = data_space.loc[data_space['space_id']!=108]\n",
        "data_space = data_space.loc[data_space['space_id']!=109]\n",
        "data_space = data_space.loc[data_space['space_id']!=120]\n",
        "data_space = data_space.loc[data_space['space_id']!=188]\n",
        "data_space = data_space.loc[data_space['space_id']!=189]\n",
        "data_space = data_space.loc[data_space['space_id']!=190]\n",
        "data_space = data_space.loc[data_space['space_id']!=191]\n",
        "data_space = data_space.drop('title', axis = 1)\n",
        "data_space = data_space.drop('lat', axis = 1)\n",
        "data_space = data_space.drop('lng', axis = 1)\n",
        "\n",
        "##### 找出最大的space_id\n",
        "data_space_id_list = data_space[\"space_id\"].tolist()\n",
        "max_space_id = data_space_id_list[len(data_space_id_list)-1]\n",
        "\n",
        "data_space"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL7vbC_9cQqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Delete specific user_id, and add 'start_time_group', 'end_time_group','weekday','Is_holiday' as new columns\n",
        "\n",
        "#####  真實 order 訂單處理  #####\n",
        "data_order = pd.read_csv(\"orders.csv\", encoding = 'big5') #若無法正確讀取原始檔，編碼方式請改為utf-8\n",
        "order_created_at = data_order[['id','created_at']]\n",
        "order_date = data_order[['id','date']]\n",
        "\n",
        "#####。刪除特定user_id(employee)\n",
        "data_order = data_order.loc[data_order['user_id'] != 1307]\n",
        "data_order = data_order.loc[data_order['user_id'] != 798]\n",
        "data_order = data_order.loc[data_order['user_id'] != 552]\n",
        "data_order = data_order.loc[data_order['user_id'] != 3]\n",
        "data_order = data_order.loc[data_order['user_id'] != 1367]\n",
        "data_order = data_order.loc[data_order['user_id'] != 2899]\n",
        "data_order = data_order.loc[data_order['user_id'] != 6027]\n",
        "data_order = data_order.loc[data_order['user_id'] != 524]\n",
        "data_order = data_order.loc[data_order['user_id'] != 7637]\n",
        "data_order = data_order.loc[data_order['user_id'] != 11161]\n",
        "data_order = data_order.loc[data_order['user_id'] != 14300]\n",
        "data_order = data_order.loc[data_order['user_id'] != 1389]\n",
        "data_order = data_order.loc[data_order['user_id'] != 100]\n",
        "data_order = data_order.loc[data_order['user_id'] != 18374]\n",
        "data_order = data_order.loc[data_order['user_id'] != 19331]\n",
        "data_order = data_order.loc[data_order['user_id'] != 1]\n",
        "data_order = data_order.loc[data_order['user_id'] != 17571]\n",
        "data_order = data_order.loc[data_order['user_id'] != 240]\n",
        "\n",
        "data_order = data_order.loc[data_order['space_id'] != 2]\n",
        "data_order = data_order.loc[data_order['space_id'] != 61]\n",
        "data_order = data_order.loc[data_order['space_id'] != 107]\n",
        "data_order = data_order.loc[data_order['space_id'] != 108]\n",
        "data_order = data_order.loc[data_order['space_id'] != 109]\n",
        "data_order = data_order.loc[data_order['space_id'] != 120]\n",
        "data_order = data_order.loc[data_order['space_id'] != 188]\n",
        "data_order = data_order.loc[data_order['space_id'] != 189]\n",
        "data_order = data_order.loc[data_order['space_id'] != 190]\n",
        "data_order = data_order.loc[data_order['space_id'] != 191]\n",
        "\n",
        "#####  刪除月票會員的會員期間訂單\n",
        "import datetime as dt\n",
        "import pytz\n",
        "data_god_account = pd.read_csv(\"god_account_view.csv\", encoding = 'utf-8')\n",
        "\n",
        "#轉datetime\n",
        "today = dt.datetime.now().astimezone(pytz.timezone('Asia/Taipei')).strftime(\"%d/%m/%Y\")\n",
        "today = dt.datetime.strptime(today, \"%d/%m/%Y\")\n",
        "\n",
        "oneday = dt.timedelta(days=1) \n",
        "yesterday = today - oneday \n",
        "data_god_account = data_god_account.fillna(yesterday) \n",
        "\n",
        "#轉成list以抽取資料\n",
        "data_order['created_at'] = pd.to_datetime(data_order['created_at']) \n",
        "data_god_account['created_at'] = pd.to_datetime(data_god_account['created_at'])\n",
        "data_god_account['deleted_at'] = pd.to_datetime(data_god_account['deleted_at'])\n",
        "\n",
        "created_at_list = data_god_account[\"created_at\"].tolist()\n",
        "deleted_at_list = data_god_account[\"deleted_at\"].tolist()\n",
        "user_id_list = data_god_account[\"user_id\"].tolist()\n",
        "\n",
        "colNames = ('id','user_id','space_id','no',\t'description',\t'date',\t'start','end','company_number','code','discount',\t'point','original_amount','amount',\t'type','status','created_at','updated_at','returned_data','hours','category')\n",
        "masterDF = pd.DataFrame(columns = colNames)\n",
        "\n",
        "#開始找出月票會員的會員期間訂單\n",
        "for i in range(len(data_god_account)):\n",
        "  temp_order = data_order[data_order['user_id'] == user_id_list[i]]\n",
        "  result = temp_order[temp_order[\"created_at\"].between(created_at_list[i], deleted_at_list[i])]\n",
        "  masterDF = masterDF.append(result,ignore_index=True)\n",
        "\n",
        "#合併至原本訂單，並刪除重複的(剔除會員期間訂單)\n",
        "last = masterDF.append(data_order, ignore_index=True)\n",
        "data_order = last.drop_duplicates(subset='id', keep=False, inplace=False)\n",
        "\n",
        "#刪除超過今天的訂單\n",
        "data_order['date']=pd.to_datetime(data_order['date'], format = '%d/%m/%Y')\n",
        "data_order = data_order[data_order['date'] <= yesterday]\n",
        "\n",
        "data_order = data_order.drop('date', axis = 1)\n",
        "data_order = pd.merge(data_order, order_date, on=['id'], how='left')\n",
        "\n",
        "print(\"Part1 finished\")\n",
        "#丟掉真實訂單中我們不需要的欄位，並且丟掉沒成立的訂單與月票訂單\n",
        "data_order = data_order.drop('user_id', axis = 1)\n",
        "data_order = data_order.drop('no', axis = 1)\n",
        "data_order = data_order.drop('description', axis = 1)\n",
        "data_order = data_order.drop('company_number', axis = 1)\n",
        "data_order = data_order.drop('code', axis = 1)\n",
        "data_order = data_order.drop('discount',axis = 1)\n",
        "data_order = data_order.drop('point', axis = 1)\n",
        "data_order = data_order.drop('original_amount', axis = 1)\n",
        "data_order = data_order.drop('amount', axis = 1)\n",
        "data_order = data_order.drop('type', axis = 1)\n",
        "data_order = data_order.drop('returned_data', axis = 1)\n",
        "data_order = data_order.drop('created_at',axis = 1)\n",
        "data_order = data_order.drop('updated_at', axis = 1)\n",
        "data_order = data_order[data_order['status'] == 2]\n",
        "data_order = data_order[data_order['category'] == 1]\n",
        "data_order.reset_index(inplace = True)\n",
        "\n",
        "#新增start_time_group跟end_time_group \n",
        "timegroup1 = ['06:00','6:00','06:30','6:30','07:00','7:00','07:30','7:30','08:00','8:00','08:30','8:30','09:00','9:00','09:30','9:30','10:00','10:30','11:00','11:30', '12:00']\n",
        "timegroup2 = ['12:00','12:30','13:00','13:30', '14:00']\n",
        "timegroup3 = ['14:00','14:30','15:00','15:30','16:00','16:30','17:00','17:30', '18:00']\n",
        "timegroup4 = ['18:00','18:30','19:00','19:30','20:00','20:30','21:00','21:30','22:00','22:30','23:00','23:30', '24:00', '24:00:00', '0:00','00:00','0:30','00:30', '01:00','1:00','01:30','1:30','02:00','2:00','02:30','2:30','03:00','3:00','03:30','3:30','04:00','4:00','04:30','4:30','05:00','5:00','05:30','5:30', '06:00', '6:00']\n",
        "\n",
        "for i in range(len(data_order)):\n",
        "  if data_order.loc[i, 'start'] in timegroup1:\n",
        "    data_order.loc[i, 'start_time_group'] = 1\n",
        "  elif data_order.loc[i, 'start'] in timegroup2:\n",
        "    data_order.loc[i, 'start_time_group'] = 2\n",
        "  elif data_order.loc[i, 'start'] in timegroup3:\n",
        "    data_order.loc[i, 'start_time_group'] = 3\n",
        "  elif data_order.loc[i, 'start'] in timegroup4:\n",
        "    data_order.loc[i, 'start_time_group'] = 4\n",
        "  if data_order.loc[i, 'end'] in timegroup1:\n",
        "    data_order.loc[i, 'end_time_group'] = 1\n",
        "  elif data_order.loc[i, 'end'] in timegroup2:\n",
        "    data_order.loc[i, 'end_time_group'] = 2\n",
        "  elif data_order.loc[i, 'end'] in timegroup3:\n",
        "    data_order.loc[i, 'end_time_group'] = 3\n",
        "  elif data_order.loc[i, 'end'] in timegroup4:\n",
        "    data_order.loc[i, 'end_time_group'] = 4\n",
        "print(\"Part2 finished\")\n",
        "\n",
        "#新增weekday跟Is_holiday\n",
        "from datetime import datetime\n",
        "for i in range(len(data_order)):\n",
        "  data_order.loc[i,'weekday'] = datetime.strptime(data_order.loc[i,'date'],'%d/%m/%Y').weekday()\n",
        "  data_order.loc[i,'weekday'] += 1\n",
        "  if (data_order.loc[i,'weekday'] == 6 or data_order.loc[i,'weekday'] == 7):\n",
        "    data_order.loc[i,'Is_holiday'] = 1\n",
        "  else:\n",
        "    data_order.loc[i,'Is_holiday'] = 0\n",
        "print(\"Part3 finished\")\n",
        "data_order"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3afHzxk8V5Co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transpose 'space_device' \n",
        "\n",
        "#####  spaces_devices轉置  #####\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "spaces_devices = pd.read_csv(\"spaces_devices.csv\")\n",
        "\n",
        "#####  去除不需要的欄  #####\n",
        "spaces_devices = spaces_devices.drop('updated_at',axis = 1)\n",
        "spaces_devices = spaces_devices.drop('info',axis = 1)\n",
        "spaces_devices = spaces_devices.drop('sub_info',axis = 1)\n",
        "spaces_devices = spaces_devices.drop('created_at',axis = 1)\n",
        "spaces_devices = spaces_devices.drop('id',axis = 1)\n",
        "\n",
        "#####  將所有的space_id列出並轉成list  #####  \n",
        "space_id = spaces_devices\n",
        "space_id = space_id.drop('device_id',axis = 1)\n",
        "space_id = space_id.drop_duplicates(subset='space_id', keep='first', inplace=False)\n",
        "space_id = space_id.reset_index(drop=True)\n",
        "space_id.sort_values(by='space_id')\n",
        "space_id_list=space_id[\"space_id\"].tolist()\n",
        "\n",
        "#####  將房間所有的device列出，並用has表示有無  #####\n",
        "colNames = ('space_id','device_id','has')\n",
        "masterDF = pd.DataFrame(columns = colNames)\n",
        "\n",
        "for i in range(len(space_id_list)):\n",
        "  temp_space_id = spaces_devices[spaces_devices['space_id'] == space_id_list[i]]\n",
        "  temp_space_id = temp_space_id.reset_index()\n",
        "  temp_device_id = temp_space_id[\"device_id\"].tolist()\n",
        "\n",
        "  for j in range(20): # 20為device的數量!!!未來有新增device的話要改\n",
        "    if (j not in temp_device_id):\n",
        "      d = {\"space_id\" : [space_id_list[i]],\n",
        "           \"device_id\" : [j],\n",
        "           \"has\":[0]}\n",
        "      df = pd.DataFrame(d)\n",
        "      masterDF = masterDF.append(df,ignore_index=True)\n",
        "    if (j in temp_device_id):\n",
        "      d = {\"space_id\" : [space_id_list[i]],\n",
        "           \"device_id\" : [j],\n",
        "           \"has\":[1]}\n",
        "      df = pd.DataFrame(d)\n",
        "      masterDF = masterDF.append(df,ignore_index=True)\n",
        "\n",
        "#####  將masterDF轉置成以space_id為列  #####  \n",
        "device_colNames = ('space_id','0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19')\n",
        "lastDF = pd.DataFrame(columns = device_colNames)\n",
        "for i in range(len(space_id_list)):\n",
        "  temp_masterDF = masterDF[masterDF['space_id'] == space_id_list[i]]\n",
        "  temp_masterDF = temp_masterDF['has'].tolist()\n",
        "  pp={\"space_id\" : space_id_list[i],\n",
        "      \"0\":temp_masterDF[0],\n",
        "      \"1\":temp_masterDF[1],\n",
        "      \"2\":temp_masterDF[2],\n",
        "      \"3\":temp_masterDF[3],\n",
        "      \"4\":temp_masterDF[4],\n",
        "      \"5\":temp_masterDF[5],\n",
        "      \"6\":temp_masterDF[6],\n",
        "      \"7\":temp_masterDF[7],\n",
        "      \"8\":temp_masterDF[8],\n",
        "      \"9\":temp_masterDF[9],\n",
        "      \"10\":temp_masterDF[10],\n",
        "      \"11\":temp_masterDF[11],\n",
        "      \"12\":temp_masterDF[12],\n",
        "      \"13\":temp_masterDF[13],\n",
        "      \"14\":temp_masterDF[14],\n",
        "      \"15\":temp_masterDF[15],\n",
        "      \"16\":temp_masterDF[16],\n",
        "      \"17\":temp_masterDF[17],\n",
        "      \"18\":temp_masterDF[18],\n",
        "      \"19\":temp_masterDF[19],\n",
        "      }\n",
        "  lastDF = lastDF.append(pp,ignore_index=True) # 合成dataframe\n",
        "lastDF = lastDF.sort_values(by='space_id')\n",
        "\n",
        "#####  將欄位型態轉成 int #####\n",
        "lastDF['0'] = lastDF['0'].astype(np.int64)\n",
        "lastDF['1'] = lastDF['1'].astype(np.int64)\n",
        "lastDF['2'] = lastDF['2'].astype(np.int64)\n",
        "lastDF['3'] = lastDF['3'].astype(np.int64)\n",
        "lastDF['4'] = lastDF['4'].astype(np.int64)\n",
        "lastDF['5'] = lastDF['5'].astype(np.int64)\n",
        "lastDF['6'] = lastDF['6'].astype(np.int64)\n",
        "lastDF['7'] = lastDF['7'].astype(np.int64)\n",
        "lastDF['8'] = lastDF['8'].astype(np.int64)\n",
        "lastDF['9'] = lastDF['9'].astype(np.int64)\n",
        "lastDF['10'] = lastDF['10'].astype(np.int64)\n",
        "lastDF['11'] = lastDF['11'].astype(np.int64)\n",
        "lastDF['12'] = lastDF['12'].astype(np.int64)\n",
        "lastDF['13'] = lastDF['13'].astype(np.int64)\n",
        "lastDF['14'] = lastDF['14'].astype(np.int64)\n",
        "lastDF['15'] = lastDF['15'].astype(np.int64)\n",
        "lastDF['16'] = lastDF['16'].astype(np.int64)\n",
        "lastDF['17'] = lastDF['17'].astype(np.int64)\n",
        "lastDF['18'] = lastDF['18'].astype(np.int64)\n",
        "lastDF['19'] = lastDF['19'].astype(np.int64)\n",
        "\n",
        "lastDF = lastDF.loc[lastDF['space_id'] != 2]\n",
        "lastDF = lastDF.loc[lastDF['space_id'] != 61]\n",
        "lastDF = lastDF.loc[lastDF['space_id'] != 107]\n",
        "lastDF = lastDF.loc[lastDF['space_id'] != 108]\n",
        "lastDF = lastDF.loc[lastDF['space_id'] != 109]\n",
        "lastDF = lastDF.loc[lastDF['space_id'] != 120]\n",
        "lastDF = lastDF.loc[lastDF['space_id'] != 188]\n",
        "lastDF = lastDF.loc[lastDF['space_id'] != 189]\n",
        "lastDF = lastDF.loc[lastDF['space_id'] != 190]\n",
        "lastDF = lastDF.loc[lastDF['space_id'] != 191]\n",
        "\n",
        "lastDF.to_csv(\"space_device (Tranfer).csv\", index=False, sep=',',encoding='utf-8')\n",
        "spaces_devices_transfer = lastDF\n",
        "spaces_devices_transfer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcsLLzudV45A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine space & order information with transpose result and create 'order_price'\n",
        "\n",
        "#####  將兩個資料表(space, order)用space_id結合  #####\n",
        "data_new = pd.merge(data_order, data_space, on=['space_id'], how='left')\n",
        "data_new = data_new.drop('index', axis = 1)\n",
        "\n",
        "#####  order price=price*hours  #####\n",
        "for i in range(len(data_new)):\n",
        "  data_new.loc[i,'order_price'] = data_new.loc[i,'price']*data_new.loc[i,'hours']\n",
        "\n",
        "##### 調整created_at日期格式\n",
        "data_new = pd.merge(data_new, order_created_at, on=['id'], how='left')\n",
        "\n",
        "#####  調整欄位順序  #####  \n",
        "data_new = data_new.loc[:, ['id','locate_id','space_id','size','hours','price','order_price','price_per_size','date', 'created_at','start','end','start_time_group','end_time_group','weekday','Is_holiday','zipcode','category','mrt','status']] \n",
        "\n",
        "#####  將轉置好的device加入  #####\n",
        "data_final = pd.merge(data_new, spaces_devices_transfer, on=['space_id'], how='left')\n",
        "\n",
        "data_final['locate_id'] = data_final['locate_id'].astype(np.int64)\n",
        "data_final['start_time_group'] = data_final['start_time_group'].astype(np.int64)\n",
        "data_final['end_time_group'] = data_final['end_time_group'].astype(np.int64)\n",
        "data_final['weekday'] = data_final['weekday'].astype(np.int64)\n",
        "data_final['Is_holiday'] = data_final['Is_holiday'].astype(np.int64)\n",
        "data_final['zipcode'] = data_final['zipcode'].astype(np.int64)\n",
        "\n",
        "data_final = data_final.sort_values(by='space_id')\n",
        "\n",
        "data_final.to_csv(\"Real_Order.csv\", index=False, sep=',', encoding = 'utf-8')\n",
        "data_final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GNqNlRJQj08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####  生成產生假訂單的資料 Space_info.csv  #####\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#####  輸入資料並整理  #####\n",
        "data_space_temp1 = data_space[['locate_id', 'space_id', 'price', 'size', 'zipcode', 'mrt']]\n",
        "data_space_temp2 = pd.read_csv(\"spaces.csv\", encoding = 'utf-8')\n",
        "data_spaces_first_time_upload = pd.read_csv(\"spaces_first_time_upload.csv\", encoding = 'utf-8')\n",
        "data_spaces_times = pd.read_csv(\"spaces_times.csv\",encoding = 'utf-8')\n",
        "\n",
        "data_space_temp2.rename(columns = {data_space_temp2.columns[0]: 'space_id'}, inplace = True)\n",
        "data_space_temp2 = data_space_temp2.loc[:, ['space_id', 'created_at', 'enabled']]\n",
        "data_spaces_first_time_upload.rename(columns = {data_spaces_first_time_upload.columns[0]: 'space_id'}, inplace = True)\n",
        "data_spaces_first_time_upload = data_spaces_first_time_upload.loc[:, ['space_id', 'updated_at']]\n",
        "\n",
        "data_space_combine1 = pd.merge(data_space_temp1, data_space_temp2, on=['space_id'], how='left')\n",
        "data_space_combine2 = pd.merge(data_space_combine1, data_spaces_first_time_upload, on=['space_id'], how='left')\n",
        "data_space_new = data_space_combine2[['locate_id', 'space_id', 'price', 'size', 'zipcode', 'created_at', 'updated_at', 'enabled', 'mrt']]\n",
        "# data_space_new\n",
        "\n",
        "#####  先合併spaces_times.csv&spaces.csv  #####\n",
        "data_spaces_times = data_spaces_times.drop('id',axis = 1)\n",
        "data_spaces_times = data_spaces_times.drop('created_at',axis = 1)\n",
        "data_spaces_times = data_spaces_times.drop('updated_at',axis = 1)\n",
        "data_spaces_times = data_spaces_times.loc[data_spaces_times['space_id']!=61]\n",
        "data_spaces_times = data_spaces_times.loc[data_spaces_times['space_id']!=107]\n",
        "data_spaces_times = data_spaces_times.loc[data_spaces_times['space_id']!=108]\n",
        "data_spaces_times = data_spaces_times.loc[data_spaces_times['space_id']!=109]\n",
        "data_spaces_times = data_spaces_times.loc[data_spaces_times['space_id']!=120]\n",
        "data_spaces_times = data_spaces_times.loc[data_spaces_times['space_id']!=188]\n",
        "data_spaces_times = data_spaces_times.loc[data_spaces_times['space_id']!=189]\n",
        "data_spaces_times = data_spaces_times.loc[data_spaces_times['space_id']!=190]\n",
        "data_spaces_times = data_spaces_times.loc[data_spaces_times['space_id']!=191]\n",
        "\n",
        "# 修正 space 資訊   \n",
        "## data_spaces_times.loc[data_spaces_times['space_id']==103] => 161\n",
        "## data_spaces_times.loc[data_spaces_times['space_id']==127] => 166\n",
        "data_spaces_times.loc[161, 'open_day'] = 1\n",
        "data_spaces_times.loc[161, 'close_day'] = 7\n",
        "data_spaces_times.loc[161, 'open_time'] = '08:00' \n",
        "\n",
        "data_spaces_times.drop(166, axis=0,inplace=True)\n",
        "data_spaces_times = data_spaces_times.sort_values(by='space_id')\n",
        "#data_spaces_times\n",
        "\n",
        "data_space_info = pd.merge(data_spaces_times, data_space_new, on=['space_id'], how='left')\n",
        "data_space_info = data_space_info[['locate_id', 'space_id', 'price', 'size', 'zipcode', 'open_day', 'close_day', 'open_time', 'close_time', 'created_at', 'updated_at', 'enabled', 'mrt']]\n",
        "\n",
        "##### 輸出成 space_info.csv 檔案 #####\n",
        "data_space_info.to_csv(\"Space_info.csv\", index=False, sep=',', encoding = 'utf-8')\n",
        "\n",
        "data_space_info"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MciuJfQ_q6o",
        "colab_type": "text"
      },
      "source": [
        "## Fake Order Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i413qSF0_Kej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import datetime\n",
        "\n",
        "###############################################\n",
        "##### Part 1: Read the spaces information #####\n",
        "###############################################\n",
        "with open('Space_info.csv', newline='', encoding='utf-8') as space_file:\n",
        "  # 讀取 CSV 檔內容，將每一列轉成一個 dictionary\n",
        "  spaces_info = csv.DictReader(space_file)\n",
        "  \n",
        "  # 以迴圈讀取指定欄位\n",
        "  locate_id = []; space_id = []; price = []; size = []; zipcode = []; updated_at = []; enabled = [];\n",
        "  open_day = []; close_day = []; open_time = []; close_time = []; created_at = []; mrt = [];\n",
        "  for i in spaces_info:\n",
        "    locate_id.append(i['locate_id'])\n",
        "    space_id.append(i['space_id'])\n",
        "    price.append(i['price'])\n",
        "    size.append(i['size'])\n",
        "    zipcode.append(i['zipcode'])\n",
        "    open_day.append(i['open_day'])\n",
        "    close_day.append(i['close_day'])\n",
        "    open_time.append(i['open_time'])\n",
        "    close_time.append(i['close_time'])\n",
        "    created_at.append(i['created_at'])\n",
        "    mrt.append(i['mrt'])\n",
        "    updated_at.append(i['updated_at']) # 20191228_updated\n",
        "    enabled.append(i['enabled'])       # 20191228_updated\n",
        "  space_file.close()\n",
        "\n",
        "locate_id = list(map(float, locate_id))\n",
        "locate_id = list(map(int, locate_id))\n",
        "space_id = list(map(int, space_id))\n",
        "price = list(map(int, price))\n",
        "size = list(map(int, size))\n",
        "zipcode = list(map(float, zipcode))\n",
        "zipcode = list(map(int, zipcode))\n",
        "open_day = list(map(int, open_day))\n",
        "close_day = list(map(int, close_day))\n",
        "enabled = list(map(int, enabled))\n",
        "\n",
        "print(\"Read the Space information successfully.\")\n",
        "\n",
        "\n",
        "##### Read the real Orders information #####\n",
        "\n",
        "with open('Real_Order.csv', newline='', encoding='utf-8') as test_file:\n",
        "\n",
        "  # 讀取 CSV 檔內容，將每一列轉成一個 dictionary\n",
        "  test_info = csv.DictReader(test_file)\n",
        "  \n",
        "  # 以迴圈讀取指定欄位\n",
        "  r_space_id = []; r_date = []; r_start = []; r_end = [];\n",
        "  r_start_time_group = []; r_end_time_group = [];\n",
        "  for i in test_info:\n",
        "    r_space_id.append(i['space_id'])\n",
        "    r_date.append(i['date'])\n",
        "    r_start.append(i['start'])\n",
        "    r_end.append(i['end'])\n",
        "    r_start_time_group.append(i['start_time_group'])\n",
        "    r_end_time_group.append(i['end_time_group'])\n",
        "  test_file.close()\n",
        "\n",
        "r_space_id = list(map(int, r_space_id))\n",
        "r_no_dupl_space_id = list(set(r_space_id)) #delete the duplicates & use set() to sort the \n",
        "r_start_time_group = list(map(int, r_start_time_group))\n",
        "r_end_time_group = list(map(int, r_end_time_group))\n",
        "\n",
        "for i in range(0, len(r_date)):\n",
        "  r_date[i] = datetime.datetime.strptime(r_date[i], \"%d/%m/%Y\")\n",
        "\n",
        "print(\"Read the Real Order information successfully.\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIlUa1Xs_KtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#########################################################################\n",
        "##### Part 2-1: Generate Fake Orders => in Current Real Orders Time #####\n",
        "#########################################################################\n",
        "end_date = max(r_date)\n",
        "format = '%H:%M'\n",
        "import pytz \n",
        "\n",
        "with open('Fake_Orders_in_Real_Orders_Time.csv', mode='w', newline='', encoding='utf-8') as f1:\n",
        "    FOrders_writer = csv.writer(f1)\n",
        "\n",
        "    order_id = 1000000    #訂單編號\n",
        "    category = 1         #普通方案\n",
        "    Is_holiday = 0       #是否為假日\n",
        "    status = 1           #沒租出去\n",
        "\n",
        "    start_time_group = 0\n",
        "    end_time_group = 0\n",
        "    morning = datetime.datetime.strptime(\"12:00\", format)     # 1: 06:00 ~ 12:00\n",
        "    noon = datetime.datetime.strptime(\"14:00\", format)        # 2: 12:00 ~ 14:00\n",
        "    afternoon = datetime.datetime.strptime(\"18:00\", format)   # 3: 14:00 ~ 18:00\n",
        "    night = datetime.datetime.strptime(\"23:59\", format)       # 4: 18:00 ~ 24:00 , 00:00 ~ 06:00\n",
        "    midnight = datetime.datetime.strptime(\"06:00\", format)\n",
        "\n",
        "    ##### Write the Fake Orders in real order time #####\n",
        "    FOrders_writer.writerow(['id', 'locate_id', 'space_id', 'hours', 'price', 'order_price', 'size', 'price_per_size', 'date', 'start', 'end', 'start_time_group', 'end_time_group', 'weekday', 'Is_holiday', 'zipcode', 'category', 'mrt', 'status'])\n",
        "    total = 4\n",
        "    count_temp = 0\n",
        "    len_count = 0\n",
        "    # arrive_end_position = 0\n",
        "\n",
        "    for i in range(0, len(r_no_dupl_space_id)):  #遍歷真實訂單中的space_id（不重複）\n",
        "      t = i\n",
        "      while(r_no_dupl_space_id[i] != space_id[t]):\n",
        "        t += 1 \n",
        "\n",
        "      ##### 計算space的創造時間 ######\n",
        "      len_of_same_space_order = r_space_id.count(r_space_id[len_count]) #計算同一間房間有多少訂單\n",
        "      len_count += len_of_same_space_order\n",
        "      \n",
        "      same_space_time_group = []\n",
        "      temp_compare_time_group = []\n",
        "\n",
        "      ##### 設定房間起始日期 #####\n",
        "      order_start = datetime.datetime.strptime(open_time[t], format) #訂單開始時間\n",
        "      order_end = datetime.datetime.strptime(close_time[t], format)  #訂單結束時間\n",
        "      if (order_start >= midnight and order_start < morning):\n",
        "        temp_compare_time_group.append(1)\n",
        "      elif (order_start >= morning and order_start < noon):\n",
        "        temp_compare_time_group.append(2)\n",
        "      elif (order_start >= noon and order_start < afternoon):\n",
        "        temp_compare_time_group.append(3)\n",
        "      else:\n",
        "        temp_compare_time_group.append(4)\n",
        "      \n",
        "      if (order_end > midnight and order_end <= morning):\n",
        "        temp_compare_time_group.append(1)\n",
        "      elif (order_end > morning and order_end <= noon):\n",
        "        temp_compare_time_group.append(2)\n",
        "      elif (order_end > noon and order_end <= afternoon):\n",
        "        temp_compare_time_group.append(3)\n",
        "      else:\n",
        "        temp_compare_time_group.append(4)\n",
        "      temp_compare_time_group = list(range(temp_compare_time_group[0], temp_compare_time_group[1] + 1))\n",
        "      #temp_compare_time_group = [1, 2, 3, 4] or [2, 3, 4] or [1, 2] etc.\n",
        "\n",
        "      for g in range(0, len_of_same_space_order):\n",
        "        if((count_temp + 1) == len(r_space_id)):\n",
        "          r_date.append('')\n",
        "\n",
        "        if(r_date[count_temp] == r_date[count_temp+1]):\n",
        "          for u in range(r_start_time_group[count_temp], r_end_time_group[count_temp] + 1):\n",
        "            same_space_time_group.append(u)\n",
        "\n",
        "        elif(r_date[count_temp] != r_date[count_temp+1]):\n",
        "          for u in range(r_start_time_group[count_temp], r_end_time_group[count_temp] + 1):\n",
        "            same_space_time_group.append(u)\n",
        "\n",
        "          diff_time_group = list(set(temp_compare_time_group) - set(same_space_time_group))\n",
        "          for k in diff_time_group:\n",
        "            if (k == 1):\n",
        "              order_start = datetime.datetime.strptime(\"09:00\", format)\n",
        "              order_end = morning\n",
        "            elif (k == 2):\n",
        "              order_start = morning\n",
        "              order_end = noon\n",
        "            elif (k == 3):\n",
        "              order_start = noon\n",
        "              order_end = afternoon\n",
        "            else:\n",
        "              order_start = afternoon\n",
        "              order_end = datetime.datetime.strptime(\"21:00\", format)\n",
        "            ##### 計算訂單租用時間 #####\n",
        "            diff = order_end - order_start \n",
        "            seconds = diff.total_seconds()\n",
        "            hours = seconds // 3600\n",
        "            minutes = (seconds % 3600) // 60\n",
        "            duration = hours + minutes/60  #訂單租用時間\n",
        "            Is_holiday = 1 if(r_date[count_temp].isoweekday() == 6 or r_date[count_temp].isoweekday() == 7) else 0\n",
        "            ##### 開始產生訂單 #####\n",
        "            FOrders_writer.writerow([order_id, locate_id[t], space_id[t], duration, price[t], price[t]*duration, size[t], price[t]/size[t], r_date[count_temp].date().strftime(\"%d/%m/%Y\"), order_start.strftime(\"%H:%M:%S\"), order_end.strftime(\"%H:%M:%S\"), k, k, r_date[count_temp].isoweekday(), Is_holiday, zipcode[t], category, mrt[t], status])\n",
        "            order_id += 1\n",
        "          same_space_time_group = []\n",
        "        count_temp += 1\n",
        "\n",
        "    print(\"Generate the \\\"Fake_Orders_in_Real_Orders_Time.csv\\\" successfully.\")\n",
        "    f1.close()\n",
        "\n",
        "###########################################################\n",
        "##### Part 2-2: Generate Fake Orders => in Empty Time #####\n",
        "###########################################################\n",
        "\n",
        "#end_date = max(r_date) # 取真實訂單中的最近時間（最靠近的值會是昨天）\n",
        "with open('Fake_Orders_in_Empty_Time.csv', mode='w', newline='', encoding='utf-8') as f2:\n",
        "  FOrders_writer = csv.writer(f2)\n",
        "\n",
        "  order_id = 2000000    #假訂單編號\n",
        "  category = 1         #普通方案\n",
        "  Is_holiday = 0       #是否為假日\n",
        "  status = 1           #沒有真實訂單\n",
        "\n",
        "  check_day = []\n",
        "  start_time_group = 0\n",
        "  end_time_group = 0\n",
        "  morning = datetime.datetime.strptime(\"12:00\", format)     # 1: 06:00 ~ 12:00\n",
        "  noon = datetime.datetime.strptime(\"14:00\", format)        # 2: 12:00 ~ 14:00\n",
        "  afternoon = datetime.datetime.strptime(\"18:00\", format)   # 3: 14:00 ~ 18:00\n",
        "  night = datetime.datetime.strptime(\"23:59\", format)       # 4: 18:00 ~ 24:00 , 00:00 ~ 06:00\n",
        "  midnight = datetime.datetime.strptime(\"06:00\", format)\n",
        "\n",
        "  ##### Write the Fake Orders #####\n",
        "  FOrders_writer.writerow(['id', 'locate_id', 'space_id', 'size', 'hours', 'price', 'order_price', 'price_per_size', 'date', 'start', 'end', 'start_time_group', 'end_time_group', 'weekday', 'Is_holiday', 'zipcode', 'category', 'mrt', 'status'])\n",
        "  for i in range(0, len(space_id)):  #space_list\n",
        "\n",
        "    ##### 計算space的創造時間 ######\n",
        "    # space_created = datetime.datetime.strptime(created_at[i], '%d%b%y:%H:%M:%S') #read info like '08FEB17:21:43:04' #2019/11/8  6:06:17 PM\n",
        "    space_created = datetime.datetime.strptime(created_at[i], '%Y-%m-%d %H:%M:%S')\n",
        "    space_created_date = datetime.datetime.strptime(space_created.strftime(\"%d/%m/%Y\"), \"%d/%m/%Y\") #空間建立時間\n",
        "    \n",
        "    if(enabled[i] == 0): ## enabled == 0 -> space 已停用\n",
        "      # space_end = datetime.datetime.strptime(updated_at[i], '%d%b%y:%H:%M:%S')   #read info like '23APR19:01:20:42'\n",
        "      space_end = datetime.datetime.strptime(updated_at[i], '%d/%m/%Y %H:%M:%S')\n",
        "      space_end_date = datetime.datetime.strptime(space_end.strftime(\"%d/%m/%Y\") , \"%d/%m/%Y\")\n",
        "      len_of_date = (space_end_date - space_created_date).days + 1\n",
        "    else:\n",
        "      len_of_date = (end_date - space_created_date).days + 1 #int 計算兩個日期間距\n",
        "    \n",
        "    ##### 設定房間起始日期 #####\n",
        "    date = datetime.datetime.strptime(space_created.strftime(\"%d/%m/%Y\"), \"%d/%m/%Y\")\n",
        "    order_start = datetime.datetime.strptime(open_time[i], format) #訂單開始時間\n",
        "    order_end = datetime.datetime.strptime(close_time[i], format)  #訂單結束時間\n",
        "    if (order_start >= midnight and order_start < morning):\n",
        "      start_time_group = 1\n",
        "    elif (order_start >= morning and order_start < noon):\n",
        "      start_time_group = 2\n",
        "    elif (order_start >= noon and order_start < afternoon):\n",
        "      start_time_group = 3\n",
        "    else:\n",
        "      start_time_group = 4\n",
        "\n",
        "    if (order_end > midnight and order_end <= morning):\n",
        "      end_time_group = 1\n",
        "    elif (order_end > morning and order_end <= noon):\n",
        "      end_time_group = 2\n",
        "    elif (order_end > noon and order_end <= afternoon):\n",
        "      end_time_group = 3\n",
        "    else:\n",
        "      end_time_group = 4\n",
        "\n",
        "    ##### 開始產生訂單 #####\n",
        "    for j in range(0, len_of_date): #根據空間的建立時間，再跑到 31/12/2019\n",
        "      start = open_time[i]  #重置每日的租用時段\n",
        "      check_day = list(range(open_day[i], close_day[i]+1))\n",
        "      \n",
        "      Is_holiday = 1 if(date.isoweekday() == 6 or date.isoweekday() == 7) else 0\n",
        "\n",
        "      if (date.isoweekday() in check_day):\n",
        "        for k in range(start_time_group, end_time_group + 1):\n",
        "          if (k == 1):\n",
        "            order_start = datetime.datetime.strptime(\"09:00\", format)\n",
        "            order_end = morning\n",
        "          elif (k == 2):\n",
        "            order_start = morning\n",
        "            order_end = noon\n",
        "          elif (k == 3):\n",
        "            order_start = noon\n",
        "            order_end = afternoon\n",
        "          else:\n",
        "            order_start = afternoon\n",
        "            order_end = datetime.datetime.strptime(\"21:00\", format)\n",
        "          ##### 計算訂單租用時間 #####\n",
        "          diff = order_end - order_start \n",
        "          seconds = diff.total_seconds()\n",
        "          hours = seconds // 3600\n",
        "          minutes = (seconds % 3600) // 60\n",
        "          duration = hours + minutes/60  #訂單租用時間\n",
        "          \n",
        "          ##### Actual write #####\n",
        "          FOrders_writer.writerow([order_id, locate_id[i], space_id[i], size[i], duration, price[i], price[i]*duration, price[i]/size[i], date.date().strftime(\"%d/%m/%Y\"), order_start.strftime(\"%H:%M:%S\"), order_end.strftime(\"%H:%M:%S\"), k, k, date.isoweekday(), Is_holiday, zipcode[i], category, mrt[i], status])\n",
        "          order_id += 1\n",
        "      date = date + datetime.timedelta(days=1)\n",
        "\n",
        "  print(\"Generate the \\\"Fake_Orders_in_Empty_Time.csv\\\" successfully.\")\n",
        "  f2.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOwJBEuPKXoY",
        "colab_type": "text"
      },
      "source": [
        "### Fake & Real Orders: Combine and Filter Overlapping Parts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcRI2g5n_K7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part 1: Combine Data \n",
        "\n",
        "#####  讀取真實訂單  #####\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "real_order = pd.read_csv(\"Real_Order.csv\",encoding = 'utf-8') #真實訂單(cat=1)\n",
        "real_order = real_order.drop('created_at',axis = 1)\n",
        "real_order = real_order.fillna(0)\n",
        "\n",
        "#####. 讀取假訂單並加上device(0~19)  #####\n",
        "fake_orders_in_real_order = pd.read_csv(\"Fake_Orders_in_Real_Orders_Time.csv\", encoding = 'utf-8')\n",
        "fake_orders_empty_time = pd.read_csv(\"Fake_Orders_in_Empty_Time.csv\", encoding = 'utf-8')\n",
        "space_device_tra = pd.read_csv(\"space_device (Tranfer).csv\", encoding = 'utf-8')\n",
        "\n",
        "fake_orders_in_real_order = pd.merge(fake_orders_in_real_order, space_device_tra, on=['space_id'], how='left')\n",
        "fake_orders_empty_time = pd.merge(fake_orders_empty_time, space_device_tra, on=['space_id'], how='left')\n",
        "\n",
        "#####  整理輸入資料的欄位  #####\n",
        "real_order.rename(columns = {real_order.columns[19]: '0'}, inplace = True)\n",
        "real_order.rename(columns = {real_order.columns[20]: '1'}, inplace = True)\n",
        "real_order.rename(columns = {real_order.columns[21]: '2'}, inplace = True)\n",
        "real_order.rename(columns = {real_order.columns[22]: '3'}, inplace = True)\n",
        "real_order.rename(columns = {real_order.columns[23]: '4'}, inplace = True)\n",
        "real_order.rename(columns = {real_order.columns[24]: '5'}, inplace = True)\n",
        "real_order.rename(columns = {real_order.columns[25]: '6'}, inplace = True)\n",
        "real_order.rename(columns = {real_order.columns[26]: '7'}, inplace = True)\n",
        "real_order.rename(columns = {real_order.columns[27]: '8'}, inplace = True)\n",
        "real_order.rename(columns = {real_order.columns[28]: '9'}, inplace = True)\n",
        "real_order = real_order.loc[:, ['id','locate_id','space_id','size','hours','price','order_price','price_per_size','date','start','end','start_time_group','end_time_group','weekday','Is_holiday','zipcode','category','mrt','status','0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19']]\n",
        "\n",
        "fake_orders_in_real_order.rename(columns = {fake_orders_in_real_order.columns[19]: '0'}, inplace = True)\n",
        "fake_orders_in_real_order.rename(columns = {fake_orders_in_real_order.columns[20]: '1'}, inplace = True)\n",
        "fake_orders_in_real_order.rename(columns = {fake_orders_in_real_order.columns[21]: '2'}, inplace = True)\n",
        "fake_orders_in_real_order.rename(columns = {fake_orders_in_real_order.columns[22]: '3'}, inplace = True)\n",
        "fake_orders_in_real_order.rename(columns = {fake_orders_in_real_order.columns[23]: '4'}, inplace = True)\n",
        "fake_orders_in_real_order.rename(columns = {fake_orders_in_real_order.columns[24]: '5'}, inplace = True)\n",
        "fake_orders_in_real_order.rename(columns = {fake_orders_in_real_order.columns[25]: '6'}, inplace = True)\n",
        "fake_orders_in_real_order.rename(columns = {fake_orders_in_real_order.columns[26]: '7'}, inplace = True)\n",
        "fake_orders_in_real_order.rename(columns = {fake_orders_in_real_order.columns[27]: '8'}, inplace = True)\n",
        "fake_orders_in_real_order.rename(columns = {fake_orders_in_real_order.columns[28]: '9'}, inplace = True)\n",
        "fake_orders_in_real_order = fake_orders_in_real_order.loc[:, ['id','locate_id','space_id','size','hours','price','order_price','price_per_size','date','start','end','start_time_group','end_time_group','weekday','Is_holiday','zipcode','category','mrt','status','0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19']]\n",
        "\n",
        "fake_orders_empty_time.rename(columns = {fake_orders_empty_time.columns[19]: '0'}, inplace = True)\n",
        "fake_orders_empty_time.rename(columns = {fake_orders_empty_time.columns[20]: '1'}, inplace = True)\n",
        "fake_orders_empty_time.rename(columns = {fake_orders_empty_time.columns[21]: '2'}, inplace = True)\n",
        "fake_orders_empty_time.rename(columns = {fake_orders_empty_time.columns[22]: '3'}, inplace = True)\n",
        "fake_orders_empty_time.rename(columns = {fake_orders_empty_time.columns[24]: '5'}, inplace = True)\n",
        "fake_orders_empty_time.rename(columns = {fake_orders_empty_time.columns[25]: '6'}, inplace = True)\n",
        "fake_orders_empty_time.rename(columns = {fake_orders_empty_time.columns[26]: '7'}, inplace = True)\n",
        "fake_orders_empty_time.rename(columns = {fake_orders_empty_time.columns[27]: '8'}, inplace = True)\n",
        "fake_orders_empty_time.rename(columns = {fake_orders_empty_time.columns[28]: '9'}, inplace = True)\n",
        "fake_orders_empty_time = fake_orders_empty_time.loc[:, ['id','locate_id','space_id','size','hours','price','order_price','price_per_size','date','start','end','start_time_group','end_time_group','weekday','Is_holiday','zipcode','category','mrt','status','0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19']]\n",
        "\n",
        "#####  合併訂單 - real order & fake orders in real order  #####\n",
        "unfinish_order = real_order.append(fake_orders_in_real_order,ignore_index=True)\n",
        "unfinish_order = unfinish_order.loc[:, ['id','locate_id','space_id','size','hours','price','order_price','price_per_size','date','start','end','start_time_group','end_time_group','weekday','Is_holiday','zipcode','category','mrt','status','0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19']]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiPe8ErJ_LPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part 2: Filter Overlapping Parts\n",
        "\n",
        "#####  開始掃描fake order empty time  #####\n",
        "colNames = ('id','locate_id',\t'space_id',\t'size',\t'hours',\t'price',\t'order_price',\t'price_per_size',\t'date',\t'start'\t,'end',\t'start_time_group',\t'end_time_group',\t'weekday',\t'Is_holiday',\t'zipcode',\t'category',\t'mrt','status','0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19')\n",
        "masterDF = pd.DataFrame(columns = colNames)\n",
        "num = max_space_id  # num為最大的space_id\n",
        "for i in range(num): \n",
        "  temp_b = fake_orders_empty_time[fake_orders_empty_time['space_id']==i]\n",
        "  temp_a = unfinish_order[unfinish_order['space_id']==i]\n",
        "  temp_a_list = temp_a[\"date\"].tolist()\n",
        "  \n",
        "  result = temp_b[temp_b['date'].map(lambda x:x not in temp_a_list)]\n",
        "\n",
        "  masterDF = masterDF.append(result,ignore_index=True)# masterDF: filted empty order\n",
        "\n",
        "#####  最終合併  #####   \n",
        "final_combimed_order = unfinish_order.append(masterDF,ignore_index=True)\n",
        "\n",
        "final_combimed_order.to_csv(\"Final Fake & Real Orders.csv\",index=False,sep=',',encoding = 'utf-8')\n",
        "final_combimed_order"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBJRXcwRYB_h",
        "colab_type": "text"
      },
      "source": [
        "## Model Trianing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPYFkXql_LwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 將資料套入 Regression model 進行預測"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O02rtTb_L5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#計算總體模型準確率\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "data = pd.read_csv(\"Final Fake & Real Orders.csv\", encoding = 'utf-8')\n",
        "x = data.loc(axis = 1)[['size', 'price_per_size','start_time_group','end_time_group','mrt', 'weekday', 'Is_holiday', 'status','0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19']]\n",
        "x['status']-=1\n",
        "labelencoder = LabelEncoder()\n",
        "x['start_time_group'] = labelencoder.fit_transform(x['start_time_group'])\n",
        "x['end_time_group'] = labelencoder.fit_transform(x['end_time_group'])\n",
        "x['mrt'] = labelencoder.fit_transform(x['mrt'])\n",
        "x['weekday'] = labelencoder.fit_transform(x['weekday'])\n",
        "x['Is_holiday'] = labelencoder.fit_transform(x['Is_holiday'])\n",
        "x['0'] = labelencoder.fit_transform(x['0'])\n",
        "x['1'] = labelencoder.fit_transform(x['1'])\n",
        "x['2'] = labelencoder.fit_transform(x['2'])\n",
        "x['3'] = labelencoder.fit_transform(x['3'])\n",
        "x['4'] = labelencoder.fit_transform(x['4'])\n",
        "x['5'] = labelencoder.fit_transform(x['5'])\n",
        "x['6'] = labelencoder.fit_transform(x['6'])\n",
        "x['7'] = labelencoder.fit_transform(x['7'])\n",
        "x['8'] = labelencoder.fit_transform(x['8'])\n",
        "x['9'] = labelencoder.fit_transform(x['9'])\n",
        "x['10'] = labelencoder.fit_transform(x['10'])\n",
        "x['11'] = labelencoder.fit_transform(x['11'])\n",
        "x['12'] = labelencoder.fit_transform(x['12'])\n",
        "x['13'] = labelencoder.fit_transform(x['13'])\n",
        "x['14'] = labelencoder.fit_transform(x['14'])\n",
        "x['15'] = labelencoder.fit_transform(x['15'])\n",
        "x['16'] = labelencoder.fit_transform(x['16'])\n",
        "x['17'] = labelencoder.fit_transform(x['17'])\n",
        "x['18'] = labelencoder.fit_transform(x['18'])\n",
        "x['19'] = labelencoder.fit_transform(x['19'])\n",
        "\n",
        "y = x['status']\n",
        "x = x.drop('status', axis = 1)\n",
        "# x = x.drop('locate_id', axis = 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=0)\n",
        "model_all = LogisticRegression().fit(X_train, y_train)\n",
        "model_all_acc = model_all.score(X_test,y_test)\n",
        "print('總體模型訓練集準確率', model_all.score(X_train,y_train))\n",
        "print('總體模型測試集準確率',model_all.score(X_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUUVdFdY4hQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#找最大的space_id\n",
        "data_find_max = pd.read_csv(\"Final Fake & Real Orders.csv\")\n",
        "x_find_max = data_find_max.loc(axis = 1)[['space_id','size', 'price_per_size','start_time_group','end_time_group','mrt', 'weekday', 'Is_holiday', 'status','0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19']]\n",
        "x_find_max.drop_duplicates(subset='space_id', keep='first', inplace=True)\n",
        "x_find_max = x_find_max.sort_values(by='space_id')\n",
        "Max = max(x_find_max['space_id'])\n",
        "count_space_ids = list(x_find_max['space_id'])\n",
        "print(Max)\n",
        "print(len(count_space_ids))\n",
        "# x_find_max\n",
        "# count_space_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2uXSMb42yKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#將只有假訂單的space id剔除掉\n",
        "data_space_sort = pd.read_csv(\"Real_Order.csv\", encoding = 'unicode_escape')\n",
        "data_space_sort.drop_duplicates(subset='space_id', keep='first', inplace=True)\n",
        "data_space_sort = data_space_sort.sort_values(by='space_id')\n",
        "searching = list(data_space_sort['space_id'])\n",
        "dont_deletes = []\n",
        "for i in range(len(count_space_ids)):\n",
        "  if count_space_ids[i] in searching:\n",
        "    dont_deletes.append(count_space_ids[i])\n",
        "count_space_ids = dont_deletes\n",
        "print(len(count_space_ids))\n",
        "# print(count_space_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRP5ENEU_MAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#計算個別模型準確率，並依照測試集準確率來決定要使用總體模型還是個別模型當作該space的模型\n",
        "#大約要執行13分鐘\n",
        "data = pd.read_csv(\"Final Fake & Real Orders.csv\")\n",
        "x_space = data.loc(axis = 1)[['space_id','size', 'price_per_size','start_time_group','end_time_group','mrt', 'weekday', 'Is_holiday', 'status','0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19']]\n",
        "x_space['status']-=1\n",
        "labelencoder = LabelEncoder()\n",
        "x_space['start_time_group'] = labelencoder.fit_transform(x_space['start_time_group'])\n",
        "x_space['end_time_group'] = labelencoder.fit_transform(x_space['end_time_group'])\n",
        "x_space['mrt'] = labelencoder.fit_transform(x_space['mrt'])\n",
        "x_space['weekday'] = labelencoder.fit_transform(x_space['weekday'])\n",
        "x_space['Is_holiday'] = labelencoder.fit_transform(x_space['Is_holiday'])\n",
        "x_space['0'] = labelencoder.fit_transform(x_space['0'])\n",
        "x_space['1'] = labelencoder.fit_transform(x_space['1'])\n",
        "x_space['2'] = labelencoder.fit_transform(x_space['2'])\n",
        "x_space['3'] = labelencoder.fit_transform(x_space['3'])\n",
        "x_space['4'] = labelencoder.fit_transform(x_space['4'])\n",
        "x_space['5'] = labelencoder.fit_transform(x_space['5'])\n",
        "x_space['6'] = labelencoder.fit_transform(x_space['6'])\n",
        "x_space['7'] = labelencoder.fit_transform(x_space['7'])\n",
        "x_space['8'] = labelencoder.fit_transform(x_space['8'])\n",
        "x_space['9'] = labelencoder.fit_transform(x_space['9'])\n",
        "x_space['10'] = labelencoder.fit_transform(x_space['10'])\n",
        "x_space['11'] = labelencoder.fit_transform(x_space['11'])\n",
        "x_space['12'] = labelencoder.fit_transform(x_space['12'])\n",
        "x_space['13'] = labelencoder.fit_transform(x_space['13'])\n",
        "x_space['14'] = labelencoder.fit_transform(x_space['14'])\n",
        "x_space['15'] = labelencoder.fit_transform(x_space['15'])\n",
        "x_space['16'] = labelencoder.fit_transform(x_space['16'])\n",
        "x_space['17'] = labelencoder.fit_transform(x_space['17'])\n",
        "x_space['18'] = labelencoder.fit_transform(x_space['18'])\n",
        "x_space['19'] = labelencoder.fit_transform(x_space['19'])\n",
        "\n",
        "space_ids = []\n",
        "acc_train = []\n",
        "acc = []\n",
        "data_size = []\n",
        "models = []\n",
        "\n",
        "for i in range(1,Max+1):\n",
        "  if i in count_space_ids:\n",
        "    x_new = x_space[x_space[\"space_id\"] == i]\n",
        "    y_new = x_new['status']\n",
        "    x_new = x_new.drop('status', axis = 1)\n",
        "    x_new = x_new.drop('space_id', axis = 1)\n",
        "    X_train_space, X_test_space, y_train_space, y_test_space = train_test_split(x_new, y_new, \n",
        "                                                                                    test_size=0.2, \n",
        "                                                                                    random_state=0)\n",
        "    model_space = LogisticRegression().fit(X_train_space, y_train_space)\n",
        "    if model_space.score(X_test_space,y_test_space) >= model_all_acc:\n",
        "      models.append(model_space)\n",
        "    else:\n",
        "      model = LogisticRegression().fit(X_train, y_train)\n",
        "      models.append(model)\n",
        "    space_ids.append(i)\n",
        "    acc_train.append(model_space.score(X_train_space,y_train_space))\n",
        "    acc.append(model_space.score(X_test_space,y_test_space))\n",
        "    data_size.append(len(x_new))\n",
        "for i in range(len(acc)):\n",
        "  print('Space ID : ', space_ids[i] , '，訓練集準確率：', acc_train[i], '，測試集準確率 : ' , acc[i],'，資料大小 : ' , data_size[i])\n",
        "print(len(space_ids))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySGndZko5Ju9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#預測每個時段的出租機率\n",
        "count = 0\n",
        "final = []\n",
        "weekdays = [0, 1, 2, 3, 4, 5, 6]\n",
        "Is_holidays = [0, 0, 0, 0, 0, 1, 1]\n",
        "start_time_groups = [0, 1, 2, 3]\n",
        "\n",
        "for i in range(len(space_ids)):\n",
        "  for j in range(len(weekdays)):\n",
        "    for k in range(len(start_time_groups)):\n",
        "      x_space_temp = x_space[x_space['space_id'] == space_ids[i]]\n",
        "      x_space_temp = x_space_temp.drop('space_id',axis=1)\n",
        "      x_space_temp = x_space_temp.drop('status',axis=1)\n",
        "      x_space_temp['start_time_group'] = start_time_groups[k]\n",
        "      x_space_temp['end_time_group'] = start_time_groups[k]\n",
        "      x_space_temp['weekday'] = weekdays[j]\n",
        "      x_space_temp['Is_holiday'] = Is_holidays[j]\n",
        "      temp = models[i].predict_proba(x_space_temp).reshape(-1)\n",
        "      final.append(temp[1])\n",
        "      print('space id', space_ids[i],' 星期', weekdays[j]+1, ' 時段', start_time_groups[k]+1,' 會被出租的機率為：', final[count])\n",
        "      count += 1\n",
        "print(len(final))\n",
        "# final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7chkRzm5Of-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#將每個出租機率依照星期、時段來分類\n",
        "weekday1timegroup1acc = []\n",
        "weekday1timegroup2acc = []\n",
        "weekday1timegroup3acc = []\n",
        "weekday1timegroup4acc = []\n",
        "weekday2timegroup1acc = []\n",
        "weekday2timegroup2acc = []\n",
        "weekday2timegroup3acc = []\n",
        "weekday2timegroup4acc = []\n",
        "weekday3timegroup1acc = []\n",
        "weekday3timegroup2acc = []\n",
        "weekday3timegroup3acc = []\n",
        "weekday3timegroup4acc = []\n",
        "weekday4timegroup1acc = []\n",
        "weekday4timegroup2acc = []\n",
        "weekday4timegroup3acc = []\n",
        "weekday4timegroup4acc = []\n",
        "weekday5timegroup1acc = []\n",
        "weekday5timegroup2acc = []\n",
        "weekday5timegroup3acc = []\n",
        "weekday5timegroup4acc = []\n",
        "weekday6timegroup1acc = []\n",
        "weekday6timegroup2acc = []\n",
        "weekday6timegroup3acc = []\n",
        "weekday6timegroup4acc = []\n",
        "weekday7timegroup1acc = []\n",
        "weekday7timegroup2acc = []\n",
        "weekday7timegroup3acc = []\n",
        "weekday7timegroup4acc = []\n",
        "total = [weekday1timegroup1acc,weekday1timegroup2acc,weekday1timegroup3acc,weekday1timegroup4acc,weekday2timegroup1acc,weekday2timegroup2acc,weekday2timegroup3acc,weekday2timegroup4acc,weekday3timegroup1acc,weekday3timegroup2acc,weekday3timegroup3acc,weekday3timegroup4acc,weekday4timegroup1acc,weekday4timegroup2acc,weekday4timegroup3acc,weekday4timegroup4acc,weekday5timegroup1acc,weekday5timegroup2acc,weekday5timegroup3acc,weekday5timegroup4acc,weekday6timegroup1acc,weekday6timegroup2acc,weekday6timegroup3acc,weekday6timegroup4acc,weekday7timegroup1acc,weekday7timegroup2acc,weekday7timegroup3acc,weekday7timegroup4acc]\n",
        "final = np.array(final)\n",
        "final = final.reshape(len(space_ids),28)\n",
        "for i in range(len(space_ids)):\n",
        "  temp = final[i]\n",
        "  for j in range(len(temp)):\n",
        "      total[j].append(temp[j])\n",
        "print(weekday1timegroup1acc)\n",
        "print(len(weekday1timegroup1acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvSpI0hh4xWB",
        "colab_type": "text"
      },
      "source": [
        "## Lead Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UicNcC-5WQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "### space_sort_資料表按照space_id排序\n",
        "data_space_sort = pd.read_csv(\"Real_Order.csv\", encoding = 'utf-8')\n",
        "data_space_sort"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MezCIkt5el3",
        "colab_type": "text"
      },
      "source": [
        "宣告space_sort資料表的資料結構"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiohFcL65ZbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "space_id = np.array(data_space_sort['space_id'])\n",
        "creat_data_space = np.array(data_space_sort['created_at'])\n",
        "actual_date_space = np.array(data_space_sort['date'])\n",
        "actual_time_space = np.array(data_space_sort['start'])\n",
        "price = np.array(data_space_sort['price'])\n",
        "###將creat日期與時間合併\n",
        "actual_data_space = np.array(actual_date_space + ' ' + actual_time_space)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V46NLeM35goV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###偵測資料數目\n",
        "number_of_data = len(data_space_sort['space_id'])\n",
        "print(\"資料筆數: \",number_of_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mI6n1lU5idh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###偵測space數量\n",
        "space_number = space_id[number_of_data-1]\n",
        "print(\"space數量: \",space_number)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcT8V7sBoWeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###偵測有使用的space_id\n",
        "used_space = set(space_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGqtHBBw5l5D",
        "colab_type": "text"
      },
      "source": [
        "計算各筆訂單的平均數，變異數，標準差"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5YHZJKg5j_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######main function\n",
        "import datetime\n",
        "import math\n",
        "a = 0   #紀錄每筆order\n",
        "b = 1   #space_id指標\n",
        "lead_time_total = np.zeros((space_number+1),dtype = float)\n",
        "variance_total = np.zeros((space_number+1),dtype = float)\n",
        "counter_total =  np.zeros((space_number+1),dtype = float)\n",
        "mean_space = np.zeros((space_number+1),dtype = float)\n",
        "\n",
        "###計算各space的總total_lead_time\n",
        "for i in range(1,space_number+1):\n",
        "  ###初始化相關陣列\n",
        "  while (space_id[a] == i): \n",
        "    date1 = actual_data_space[a]\n",
        "    date2 = creat_data_space[a]\n",
        "    start = datetime.datetime.strptime(date2, '%d/%m/%Y %H:%M:%S')\n",
        "    end = datetime.datetime.strptime(date1, '%d/%m/%Y %H:%M')\n",
        "    time = end - start\n",
        "    ###將秒轉為小時  \n",
        "    lead_time_total[b] += time.total_seconds()/3600  \n",
        "    counter_total[b] += 1\n",
        "    a += 1 \n",
        "    if(a == number_of_data):break     \n",
        "  else:\n",
        "    b += 1 \n",
        "  if(a == number_of_data):break\n",
        "\n",
        "###計算平均lead_time\n",
        "for i in range(1,space_number+1):\n",
        "  mean_space[i] = lead_time_total[i]/counter_total[i]\n",
        "\n",
        "\n",
        "###計算各space的總variance_total\n",
        "a = 0\n",
        "b = 1\n",
        "variance_total = np.zeros((space_number+1),dtype = float)\n",
        "counter_total =  np.zeros((space_number+1),dtype = float)\n",
        "variance_space = np.zeros((space_number+1),dtype = float)\n",
        "positive_standard_space = np.zeros((space_number+1),dtype = float)\n",
        "negative_standard_space = np.zeros((space_number+1),dtype = float)\n",
        "for i in range(1,space_number+1):\n",
        "  ###初始化相關陣列\n",
        "  while (space_id[a] == i): \n",
        "    date1 = actual_data_space[a]\n",
        "    date2 = creat_data_space[a]\n",
        "    start = datetime.datetime.strptime(date2, '%d/%m/%Y %H:%M:%S')\n",
        "    end = datetime.datetime.strptime(date1, '%d/%m/%Y %H:%M')\n",
        "    time = end - start \n",
        "    variance_total[b] += pow((time.total_seconds()/3600) - mean_space[b],2) \n",
        "    counter_total[b] += 1\n",
        "    a += 1\n",
        "    if(a == number_of_data):break \n",
        "  else:\n",
        "    b += 1 \n",
        "  if(a == number_of_data):break\n",
        "\n",
        "###計算Variance\n",
        "for i in range(1,space_number+1):\n",
        "  variance_space[i] = variance_total[i]/counter_total[i]\n",
        "\n",
        "###計算positive_standard_space\n",
        "for i in range(1,space_number+1):\n",
        "  positive_standard_space[i] = pow(variance_space[i],0.5)\n",
        "\n",
        "###計算negative_standard_space\n",
        "for i in range(1,space_number+1):\n",
        "  negative_standard_space[i] = positive_standard_space[i] * -1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXtcXNcj5qTw",
        "colab_type": "text"
      },
      "source": [
        "相關資料陣列詳解"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTfoGIJZ5rSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###平均lead_time查詢\n",
        "###假設查詢space1的平均lead_time\n",
        "mean_space[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slCidjhs5tFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###正標準差查詢\n",
        "###假設查詢space1的正標準差\n",
        "positive_standard_space[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wS6gLAg5uea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###負標準差查詢\n",
        "###假設查詢space1的負標準差\n",
        "negative_standard_space[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fGS-25n3K9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#找最大的space_id\n",
        "data_find_max = pd.read_csv(\"Final Fake & Real Orders.csv\")\n",
        "x_find_max = data_find_max.loc(axis = 1)[['space_id','size', 'price_per_size','start_time_group','end_time_group','mrt', 'weekday', 'Is_holiday', 'status','0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19']]\n",
        "x_find_max.drop_duplicates(subset='space_id', keep='first', inplace=True)\n",
        "x_find_max = x_find_max.sort_values(by='space_id')\n",
        "Max = max(x_find_max['space_id'])\n",
        "count_space_ids = list(x_find_max['space_id'])\n",
        "print(Max)\n",
        "print(len(count_space_ids))\n",
        "# x_find_max\n",
        "# count_space_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hud2_NJL3Lyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#將只有假訂單的space id剔除掉\n",
        "data_space_sort.drop_duplicates(subset='space_id', keep='first', inplace=True)\n",
        "data_space_sort = data_space_sort.sort_values(by='space_id')\n",
        "searching = list(data_space_sort['space_id'])\n",
        "dont_deletes = []\n",
        "for i in range(len(count_space_ids)):\n",
        "  if count_space_ids[i] in searching:\n",
        "    dont_deletes.append(count_space_ids[i])\n",
        "count_space_ids = dont_deletes\n",
        "print(len(count_space_ids))\n",
        "# print(count_space_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXPFNWm03PCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#將有空值的lead time剔除掉\n",
        "new_mean_space = []\n",
        "new_positive_standard_space = []\n",
        "new_negative_standard_space = []\n",
        "for i in range(len(mean_space)):\n",
        "  if i in count_space_ids:\n",
        "    new_mean_space.append(mean_space[i])\n",
        "    new_positive_standard_space.append(positive_standard_space[i])\n",
        "    new_negative_standard_space.append(negative_standard_space[i])\n",
        "print(len(new_mean_space))\n",
        "print(len(new_positive_standard_space))\n",
        "print(len(new_negative_standard_space))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af684Yuh54bq",
        "colab_type": "text"
      },
      "source": [
        "將資料寫入csv檔案中"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5TWEhR656eU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "from pandas.core.frame import DataFrame\n",
        "table1 = {'space_id' : space_ids, 'lead_time' : new_mean_space, '+1 standard' : new_positive_standard_space, '-1 standard' : new_negative_standard_space,'weekday1 timegroup1 acc' : weekday1timegroup1acc,'weekday1 timegroup2 acc' : weekday1timegroup2acc,'weekday1 timegroup3 acc' : weekday1timegroup3acc ,'weekday1 timegroup4 acc' : weekday1timegroup4acc, 'weekday2 timegroup1 acc' : weekday2timegroup1acc, 'weekday2 timegroup2 acc' : weekday2timegroup2acc, 'weekday2 timegroup3 acc' : weekday2timegroup3acc, 'weekday2 timegroup4 acc' : weekday2timegroup4acc, 'weekday3 timegroup1 acc' : weekday3timegroup1acc, 'weekday3 timegroup2 acc' : weekday3timegroup2acc, 'weekday3 timegroup3 acc' : weekday3timegroup3acc, 'weekday3 timegroup4 acc' : weekday3timegroup4acc, 'weekday4 timegroup1 acc' : weekday4timegroup1acc, 'weekday4 timegroup2 acc' : weekday4timegroup2acc, 'weekday4 timegroup3 acc' : weekday4timegroup3acc, 'weekday4 timegroup4 acc' : weekday4timegroup4acc, 'weekday5 timegroup1 acc' : weekday5timegroup1acc, 'weekday5 timegroup2 acc' : weekday5timegroup2acc, 'weekday5 timegroup3 acc' : weekday5timegroup3acc, 'weekday5 timegroup4 acc' : weekday5timegroup4acc, 'weekday6 timegroup1 acc' : weekday6timegroup1acc, 'weekday6 timegroup2 acc' : weekday6timegroup2acc, 'weekday6 timegroup3 acc' : weekday6timegroup3acc, 'weekday6 timegroup4 acc' : weekday6timegroup4acc, 'weekday7 timegroup1 acc' : weekday7timegroup1acc, 'weekday7 timegroup2 acc' : weekday7timegroup2acc, 'weekday7 timegroup3 acc' : weekday7timegroup3acc, 'weekday7 timegroup4 acc' : weekday7timegroup4acc}\n",
        "data1 = DataFrame(table1)\n",
        "data1.set_index('space_id', inplace=True)\n",
        "data1.to_csv('final_table.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZZ80TIhZXiq",
        "colab_type": "text"
      },
      "source": [
        "## Price Predicting & Setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWh05iqI5_zD",
        "colab_type": "text"
      },
      "source": [
        "讀取模型資料表"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbFHNRyrjbZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### space_sort_資料表按照space_id排序\n",
        "data_model = pd.read_csv(\"final_table.csv\", encoding = 'utf-8')\n",
        "data_model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfuXGOkZ6CLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weekday1_timegroup1_acc = np.array(data_model['weekday1 timegroup1 acc'])\n",
        "weekday1_timegroup2_acc = np.array(data_model['weekday1 timegroup2 acc'])\n",
        "weekday1_timegroup3_acc = np.array(data_model['weekday1 timegroup3 acc'])\n",
        "weekday1_timegroup4_acc = np.array(data_model['weekday1 timegroup4 acc'])\n",
        "weekday2_timegroup1_acc = np.array(data_model['weekday2 timegroup1 acc'])\n",
        "weekday2_timegroup2_acc = np.array(data_model['weekday2 timegroup2 acc'])\n",
        "weekday2_timegroup3_acc = np.array(data_model['weekday2 timegroup3 acc'])\n",
        "weekday2_timegroup4_acc = np.array(data_model['weekday2 timegroup4 acc'])\n",
        "weekday3_timegroup1_acc = np.array(data_model['weekday3 timegroup1 acc'])\n",
        "weekday3_timegroup2_acc = np.array(data_model['weekday3 timegroup2 acc'])\n",
        "weekday3_timegroup3_acc = np.array(data_model['weekday3 timegroup3 acc'])\n",
        "weekday3_timegroup4_acc = np.array(data_model['weekday3 timegroup4 acc'])\n",
        "weekday4_timegroup1_acc = np.array(data_model['weekday4 timegroup1 acc'])\n",
        "weekday4_timegroup2_acc = np.array(data_model['weekday4 timegroup2 acc'])\n",
        "weekday4_timegroup3_acc = np.array(data_model['weekday4 timegroup3 acc'])\n",
        "weekday4_timegroup4_acc = np.array(data_model['weekday4 timegroup4 acc'])\n",
        "weekday5_timegroup1_acc = np.array(data_model['weekday5 timegroup1 acc'])\n",
        "weekday5_timegroup2_acc = np.array(data_model['weekday5 timegroup2 acc'])\n",
        "weekday5_timegroup3_acc = np.array(data_model['weekday5 timegroup3 acc'])\n",
        "weekday5_timegroup4_acc = np.array(data_model['weekday5 timegroup4 acc'])\n",
        "weekday6_timegroup1_acc = np.array(data_model['weekday6 timegroup1 acc'])\n",
        "weekday6_timegroup2_acc = np.array(data_model['weekday6 timegroup2 acc'])\n",
        "weekday6_timegroup3_acc = np.array(data_model['weekday6 timegroup3 acc'])\n",
        "weekday6_timegroup4_acc = np.array(data_model['weekday6 timegroup4 acc'])\n",
        "weekday7_timegroup1_acc = np.array(data_model['weekday7 timegroup1 acc'])\n",
        "weekday7_timegroup2_acc = np.array(data_model['weekday7 timegroup2 acc'])\n",
        "weekday7_timegroup3_acc = np.array(data_model['weekday7 timegroup3 acc'])\n",
        "weekday7_timegroup4_acc = np.array(data_model['weekday7 timegroup4 acc'])\n",
        "model_space_id = np.array(data_model['space_id'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we5ZdH6u6GXM",
        "colab_type": "text"
      },
      "source": [
        "輸入並判斷程式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BcXUr6p6ES8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###價錢判斷函式(acc,price)\n",
        "def price_predict(x,y):\n",
        "  global total_price,price_now\n",
        "  if(x*100<60):\n",
        "    y = price[np.where(space_id == space_id_input)][1]\n",
        "  elif(60 <= x*100 < 75):\n",
        "    y = price[np.where(space_id == space_id_input)][1]*1.05\n",
        "  elif(75 <= x*100 ):\n",
        "    y = price[np.where(space_id == space_id_input)][1]*1.1\n",
        "  total_price += y\n",
        "  ###price_now為儲存訂單最後一小時的價格,在有30分的情況需要扣掉的時候用到\n",
        "  price_now = y\n",
        "\n",
        "\n",
        "###時間函式(start_time_hour, end_time_hour)\n",
        "###算出時間差並套入main_function\n",
        "def time_hour(x,y):\n",
        "  global total_time,total_price,price_now\n",
        "  a = math.ceil(y-x)\n",
        "  b = math.floor(y-x)\n",
        "  for i in range (0,a+1):\n",
        "    main(x)\n",
        "    x+=1\n",
        "  ###判斷是否有30分鐘的訂單\n",
        "  if((end_time_hour-start_time_hour)>b):\n",
        "    ###若為是,因為30分鐘程式會把它算新的1h,最後總金額要再減掉當初多加的另1半的價格。\n",
        "    total_price = total_price - (price_now/2)\n",
        "\n",
        "\n",
        "\n",
        "###輸入時間日期\n",
        "space_id_input =int(input('請輸入space_id(number): '))\n",
        "start_time = input('請輸入起始時間(YYYY/mm/dd HH:MM:ss): ')\n",
        "end_time = input('請輸入結束時間(YYYY/mm/dd HH:MM:ss): ')\n",
        "weekday =int(input('請輸入星期幾(number): '))\n",
        "\n",
        "###時間格式化\n",
        "start_time = datetime.datetime.strptime(start_time,'%Y/%m/%d %H:%M:%S')\n",
        "end_time = datetime.datetime.strptime(end_time,'%Y/%m/%d %H:%M:%S')\n",
        "###調整為台灣時區\n",
        "today = (datetime.datetime.now()+datetime.timedelta(hours=8)).strftime(\"%Y/%m/%d %H:%M:%S\")\n",
        "today = datetime.datetime.strptime(today,'%Y/%m/%d %H:%M:%S')\n",
        "start_time_hour = start_time.hour+(start_time.minute/60)\n",
        "end_time_hour= end_time.hour+(end_time.minute/60)\n",
        "\n",
        "###main function\n",
        "def main (time_hour):\n",
        "  global weekday, price_now, total_price\n",
        "  mean = positive_standard = negative_standard = 0\n",
        "  ###以下判斷訂單的weekday,timegroup,並取出模型在對應時間的預測機率(acc)\n",
        "  if (weekday == 1):\n",
        "    if (6<=time_hour<12):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday1_timegroup1_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (12<=time_hour<14):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday1_timegroup2_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (14<=time_hour<=18):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday1_timegroup3_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (18<=time_hour<24 or 0<=time_hour<6):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday1_timegroup4_acc[np.where(model_space_id == space_id_input)]\n",
        "\n",
        "  if (weekday == 2):\n",
        "    if (6<=time_hour<12):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday2_timegroup1_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (12<=time_hour<14):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday2_timegroup2_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (14<=time_hour<=18):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday2_timegroup3_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (18<=time_hour<24 or 0<=time_hour<6):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday2_timegroup4_acc[np.where(model_space_id == space_id_input)]\n",
        "\n",
        "  if (weekday == 3):\n",
        "    if (6<=time_hour<12):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday3_timegroup1_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (12<=time_hour<14):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday3_timegroup2_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (14<=time_hour<=18):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday3_timegroup3_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (18<=time_hour<24 or 0<=time_hour<6):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday3_timegroup4_acc[np.where(model_space_id == space_id_input)]\n",
        "\n",
        "  if (weekday == 4):\n",
        "    if (6<=time_hour<12):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday4_timegroup1_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (12<=time_hour<14):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday4_timegroup2_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (14<=time_hour<=18):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday4_timegroup3_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (18<=time_hour<24 or 0<=time_hour<6):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday4_timegroup4_acc[np.where(model_space_id == space_id_input)]\n",
        " \n",
        "  if (weekday == 5):\n",
        "    if (6<=time_hour<12):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday5_timegroup1_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (12<=time_hour<14):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday5_timegroup2_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (14<=time_hour<=18):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday5_timegroup3_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (18<=time_hour<24 or 0<=time_hour<6):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday5_timegroup4_acc[np.where(model_space_id == space_id_input)]\n",
        "\n",
        "  if (weekday == 6):\n",
        "    if (6<=time_hour<12):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday6_timegroup1_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (12<=time_hour<14):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday6_timegroup2_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (14<=time_hour<=18):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday6_timegroup3_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (18<=time_hour<24 or 0<=time_hour<6):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday6_timegroup4_acc[np.where(model_space_id == space_id_input)]\n",
        "\n",
        "  if (weekday == 7):\n",
        "    if (6<=time_hour<12):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday7_timegroup1_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (12<=time_hour<14):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday7_timegroup2_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (14<=time_hour<=18):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday7_timegroup3_acc[np.where(model_space_id == space_id_input)]\n",
        "    elif (18<=time_hour<24 or 0<=time_hour<6):\n",
        "      mean = mean_space[space_id_input]\n",
        "      positive_standard = positive_standard_space[space_id_input]\n",
        "      negative_standard = negative_standard_space[space_id_input]\n",
        "      acc = weekday7_timegroup4_acc[np.where(model_space_id == space_id_input)]\n",
        "\n",
        "  ###計算lead_time\n",
        "  distance_time = (start_time - today).total_seconds()/3600\n",
        "  \n",
        "  ###判斷是否符合標準差\n",
        "  predict_price = 0 \n",
        "  if((distance_time - mean)>0):###lead_time為正\n",
        "    if((distance_time - mean) > positive_standard):\n",
        "      ###大於標準差,金額維持不變\n",
        "      total_price += price[np.where(space_id == space_id_input)][1]\n",
        "      ###price_now為儲存訂單最後一小時的價格,在有30分的情況需要扣掉的時候用到\n",
        "      price_now = price[np.where(space_id == space_id_input)][1]\n",
        "    elif((distance_time - mean) < positive_standard):\n",
        "      ###標準差內,套用預測模型\n",
        "      price_predict(acc, predict_price)\n",
        "  elif((distance_time - mean) < 0):###lead_time為負\n",
        "    if((distance_time - mean) < negative_standard):\n",
        "      ###大於標準差,金額維持不變\n",
        "      total_price += price[np.where(space_id == space_id_input)][1]\n",
        "      ###price_now為儲存訂單最後一小時的價格,在有30分的情況需要扣掉的時候用到\n",
        "      price_now = price[np.where(space_id == space_id_input)][1]\n",
        "    elif((distance_time - mean) > negative_standard):\n",
        "      ###標準差內,套用預測模型\n",
        "      price_predict(acc, predict_price)\n",
        "\n",
        "\n",
        "\n",
        "###開始呼叫function\n",
        "total_price = 0\n",
        "total_time = 0\n",
        "time_hour(start_time_hour, end_time_hour)\n",
        "print('價格為: ', total_price)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}